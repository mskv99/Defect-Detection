{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install the required packages for YOLOv8 and Comet ML\n",
        "!pip install ultralytics comet_ml torch torchvision"
      ],
      "metadata": {
        "id": "aJ2CSPARXeJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your Comet Api Key\n",
        "!export COMET_API_KEY='Blj8bZW6JvGDYje5CMFHMe9AR'"
      ],
      "metadata": {
        "id": "6KgjMwl3Xjai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import comet_ml\n",
        "\n",
        "comet_ml.init(project_name=\"rt-detr\")"
      ],
      "metadata": {
        "id": "Qg_uPpQkXncr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvEPcczwF116"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "def set_random_seed(seed):\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "\n",
        "set_random_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxJqPWF9I5lH"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/Defect_Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "03687c1afce047508dd2e3f8e4e1f1c1",
            "c70fbeda19564c109bfc8fdb56800962",
            "34ce3d550a464cb09a7a6bad8e192c72",
            "3a10a967a52e4a5c8f7ea198494e3f74",
            "922f1db598764384873f93057cb41fea",
            "298b5a4ae2474c46be31211249646573",
            "ecd9a53da50c41b8b1b62caaafa76f3d",
            "5cd996d8823d46debdbe5363faab4e89",
            "c79504cdff644537a518272d6d54c866",
            "28c91ea4d1584ba49a9be6ff3cf4b5fc",
            "49ba7c811fea4f4aa67a9b80d8e6e600"
          ]
        },
        "id": "Nv5xMJR3GBi_",
        "outputId": "5d07de70-942e-4690-c3e7-50df4c46735d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading file\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/66.2M [00:00<?, ?iB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03687c1afce047508dd2e3f8e4e1f1c1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Download dataset.\n",
        "def download_file(url, save_name):\n",
        "    if not os.path.exists(save_name):\n",
        "        print(f\"Downloading file\")\n",
        "        file = requests.get(url, stream=True)\n",
        "        total_size = int(file.headers.get('content-length', 0))\n",
        "        block_size = 1024\n",
        "        progress_bar = tqdm(\n",
        "            total=total_size,\n",
        "            unit='iB',\n",
        "            unit_scale=True\n",
        "        )\n",
        "        with open(os.path.join(save_name), 'wb') as f:\n",
        "            for data in file.iter_content(block_size):\n",
        "                progress_bar.update(len(data))\n",
        "                f.write(data)\n",
        "        progress_bar.close()\n",
        "    else:\n",
        "        print('File already present')\n",
        "\n",
        "download_file(\n",
        "    'https://app.roboflow.com/ds/Gi7A06UnbM?key=fl4u4rF4Eq',\n",
        "    '/content/Defect_Data/defects.zip'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC-GIhAiGFFT",
        "outputId": "2b68c4bc-f627-4652-9486-b10a7e4bd884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted all\n"
          ]
        }
      ],
      "source": [
        "# Unzip the data file\n",
        "def unzip(zip_file=None):\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_file) as z:\n",
        "            z.extractall(\"./\")\n",
        "            print(\"Extracted all\")\n",
        "    except:\n",
        "        print(\"Invalid file\")\n",
        "\n",
        "unzip('/content/Defect_Data/defects.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsmZRqVpJMVr"
      },
      "outputs": [],
      "source": [
        "%mv /content/test /content/train /content/valid /content/Defect_Data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkMgG2dnc8cr",
        "outputId": "1ff68912-4ed2-45ea-91b8-2c269d8c994b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/rtdetr-l.pt to 'rtdetr-l.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63.4M/63.4M [00:00<00:00, 256MB/s]\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import RTDETR\n",
        "\n",
        "model_name = \"rtdetr-l.pt\"\n",
        "dataset_name = \"/content/data.yaml\"\n",
        "\n",
        "# Initialize YOLO Model\n",
        "#model = YOLO(f\"{model_name}.pt\")\n",
        "\n",
        "# Load a COCO-pretrained RT-DETR-l model\n",
        "model = RTDETR(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSiDMgrqoCY4"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "from ultralytics import settings\n",
        "settings.update({'comet': True})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUrxr7N00IOY"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nqxltDv2Cxr"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "import yaml\n",
        "\n",
        "with open('data.yaml', 'r') as read_file:\n",
        "  content = yaml.safe_load(read_file)\n",
        "  content['train'] = '/content/Defect_Data/train/images'\n",
        "  content['val'] = '/content/Defect_Data/valid/images'\n",
        "  content['test'] = '/content/Defect_Data/test/images'\n",
        "\n",
        "with open('new_data.yaml','w') as dump_file:\n",
        "  yaml.dump(content,dump_file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRNZYuDCoh1l"
      },
      "source": [
        "# Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqmiW4BxJfu3"
      },
      "outputs": [],
      "source": [
        "results = model.train(\n",
        "    data = dataset_name,\n",
        "    project = 'RT-DETR',\n",
        "    epochs = 50,\n",
        "    imgsz = 640,\n",
        "    batch = 10,\n",
        "    workers = 2,\n",
        "    seed = 42,\n",
        "    deterministic = True,\n",
        "    plots = True,\n",
        "    save_period = 10,\n",
        "    save = False,\n",
        "    optimizer = 'SGD',\n",
        "    verbose = False,\n",
        "    cos_lr = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoJhLC2wJXaG",
        "outputId": "cad66c59-9d2e-4d16-a1d8-b530d924ce20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.225 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "rt-detr-l summary: 498 layers, 31989905 parameters, 0 gradients\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Defect_Data/valid/labels.cache... 83 images, 15 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:07<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         83        290       0.87      0.819      0.904      0.547\n",
            "                bridge         83         79      0.913      0.927      0.977      0.559\n",
            "                   gap         83         85      0.792      0.576       0.77      0.393\n",
            "                  sraf         83        126      0.906      0.952      0.967      0.689\n",
            "Speed: 0.8ms preprocess, 53.1ms inference, 0.0ms loss, 7.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0.55866,     0.39342,     0.68902])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from ultralytics import RTDETR\n",
        "model = RTDETR('/content/RT-DETR/train/weights/last.pt')\n",
        "dataset_name = '/content/data.yaml'\n",
        "# Validate the model\n",
        "metrics = model.val(data = dataset_name)  # no arguments needed, dataset and settings remembered\n",
        "metrics.box.map    # map50-95\n",
        "metrics.box.map50  # map50\n",
        "metrics.box.map75  # map75\n",
        "metrics.box.maps   # a list contains map50-95 of each category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_vCYb8MpbXJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "validation_result = pd.DataFrame({\n",
        "    'Class': ['all', 'bridge','gap','sraf'],\n",
        "    'Images':[83,83,83,83],\n",
        "    'Instances':[290,79,85,126],\n",
        "    'P':[0.87,0.913, 0.792, 0.906],\n",
        "    'R':[0.819, 0.927,0.576, 0.952],\n",
        "    'mAP50':[0.904, 0.977, 0.77, 0.967],\n",
        "    'mAP50-95':[0.547, 0.559, 0.393, 0.689]\n",
        "})\n",
        "\n",
        "validation_result.to_csv('/content/drive/MyDrive/metrics/rtdetrl_new_val_.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RRNPnjNqReV"
      },
      "outputs": [],
      "source": [
        "%cp /content/RT-DETR/train/weights/rtdetr_l_new.pt /content/drive/MyDrive/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVPbMyJrNn5l"
      },
      "outputs": [],
      "source": [
        "test_img = glob.glob('/content/Defect_Data/test/images/*.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rz9fNKBFCmwt",
        "outputId": "17bfdac2-815e-4f3b-eeeb-3b69207d4633"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 640x640 4 srafs, 1: 640x640 3 bridges, 2: 640x640 6 gaps, 3: 640x640 (no detections), 4: 640x640 3 gaps, 5: 640x640 7 gaps, 6: 640x640 (no detections), 7: 640x640 3 gaps, 8: 640x640 4 srafs, 9: 640x640 10 gaps, 10: 640x640 5 bridges, 11: 640x640 4 srafs, 12: 640x640 4 bridges, 13: 640x640 4 srafs, 14: 640x640 4 srafs, 15: 640x640 4 srafs, 16: 640x640 4 srafs, 17: 640x640 2 bridges, 18: 640x640 6 bridges, 19: 640x640 3 bridges, 20: 640x640 3 bridges, 21: 640x640 5 srafs, 22: 640x640 2 bridges, 23: 640x640 5 srafs, 24: 640x640 6 bridges, 25: 640x640 (no detections), 26: 640x640 9 gaps, 27: 640x640 6 srafs, 28: 640x640 1 bridge, 29: 640x640 5 bridges, 30: 640x640 4 srafs, 31: 640x640 10 gaps, 32: 640x640 4 srafs, 33: 640x640 4 srafs, 34: 640x640 5 bridges, 35: 640x640 3 bridges, 36: 640x640 6 gaps, 1249.5ms\n",
            "Speed: 1.7ms preprocess, 33.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "\n",
        "\n",
        "# Run inference on 'bus.jpg'\n",
        "test_results = model(test_img, conf = 0.45 )  # results list\n",
        "\n",
        "# Show the results\n",
        "for r in test_results:\n",
        "    im_array = r.plot()  # plot a BGR numpy array of predictions\n",
        "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
        "    im.show()  # show image\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cp -r /content/runs/detect/RTDETRl/ /content/drive/MyDrive/inference_outputs/RTDETR/"
      ],
      "metadata": {
        "id": "0kZ6jkuco4Ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCrVHkKBOkCd"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Run inference on 'bus.jpg' with arguments\n",
        "model.predict(test_img, save=True, imgsz=640, conf=0.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1y8b3YQmW-Y"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "def visualize(INFER_DIR):\n",
        "# Visualize inference images.\n",
        "    #INFER_PATH = f\"runs/detect/{INFER_DIR}\"\n",
        "    infer_images = glob.glob(f\"{INFER_DIR}/*.jpg\")\n",
        "    print(infer_images)\n",
        "    for pred_image in infer_images:\n",
        "      display(Image(filename=pred_image))\n",
        "      print('\\n')\n",
        "        # image = cv2.imread(pred_image)\n",
        "        # plt.figure(figsize=(10, 10))\n",
        "        # plt.imshow(image[:, :, ::-1])\n",
        "        # plt.axis('off')\n",
        "        # plt.show()\n",
        "\n",
        "visualize('/content/runs/detect/predict')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import model from gdrive and check reproductability\n"
      ],
      "metadata": {
        "id": "VbPsoy5AEe02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import RTDETR\n",
        "\n",
        "model = RTDETR('/content/drive/MyDrive/models/rtdetr_l_new.pt')\n",
        "\n",
        "metrics = model.val(data = '/content/new_data.yaml')\n",
        "metrics.box.map    # map50-95\n",
        "metrics.box.map50  # map50\n",
        "metrics.box.map75  # map75\n",
        "metrics.box.maps   # a list contains map50-95 of each category"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1iX2g9pE_7O",
        "outputId": "9470bc75-20cf-4878-d5e4-830a5cde17e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.226 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "rt-detr-l summary: 498 layers, 31989905 parameters, 0 gradients\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 31.4MB/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Defect_Data/valid/labels... 83 images, 15 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:00<00:00, 1652.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Defect_Data/valid/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:07<00:00,  1.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         83        290       0.87      0.819      0.904      0.547\n",
            "                bridge         83         79      0.913      0.927      0.977      0.559\n",
            "                   gap         83         85      0.792      0.576       0.77      0.393\n",
            "                  sraf         83        126      0.906      0.952      0.967      0.689\n",
            "Speed: 4.8ms preprocess, 62.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val4\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0.55866,     0.39342,     0.68902])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_x = RTDETR('/content/drive/MyDrive/models/rtdetr_x.pt')\n",
        "\n",
        "metrics_x = model_x.val(data = '/content/new_data.yaml')\n",
        "metrics_x.box.map    # map50-95\n",
        "metrics_x.box.map50  # map50\n",
        "metrics_x.box.map75  # map75\n",
        "metrics_x.box.maps   # a list contains map50-95 of each category"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbr9PcjwHXDp",
        "outputId": "38bb0671-eb56-4770-90e9-486d49d91569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.226 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "rt-detr-l summary: 498 layers, 31989905 parameters, 0 gradients\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Defect_Data/valid/labels.cache... 83 images, 15 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:07<00:00,  1.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         83        290      0.872       0.84      0.907       0.53\n",
            "                bridge         83         79       0.92      0.949      0.985      0.555\n",
            "                   gap         83         85      0.786      0.612      0.769      0.396\n",
            "                  sraf         83        126      0.911       0.96      0.969      0.638\n",
            "Speed: 5.1ms preprocess, 49.1ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val5\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0.55454,      0.3959,     0.63825])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-g1fSBLo7Jb"
      },
      "source": [
        "# Activation maps vizualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kbZ-JfVkJB4"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import cv2 as cv\n",
        "import argparse\n",
        "from torchvision import models, transforms\n",
        "\n",
        "\n",
        "# load the model\n",
        "model = models.resnet50(pretrained=True)\n",
        "print(model)\n",
        "model_weights = [] # we will save the conv layer weights in this list\n",
        "conv_layers = [] # we will save the 49 conv layers in this list\n",
        "# get all the model children as list\n",
        "model_children = list(model.children())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow9A72j0kVRj",
        "outputId": "1b89d0b0-cb28-4f2f-ae5c-d01eee64d29c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total convolutional layers: 49\n"
          ]
        }
      ],
      "source": [
        "\n",
        "counter = 0\n",
        "# append all the conv layers and their respective weights to the list\n",
        "for i in range(len(model_children)):\n",
        "    if type(model_children[i]) == nn.Conv2d:\n",
        "        counter += 1\n",
        "        model_weights.append(model_children[i].weight)\n",
        "        conv_layers.append(model_children[i])\n",
        "    elif type(model_children[i]) == nn.Sequential:\n",
        "        for j in range(len(model_children[i])):\n",
        "            for child in model_children[i][j].children():\n",
        "                if type(child) == nn.Conv2d:\n",
        "                    counter += 1\n",
        "                    model_weights.append(child.weight)\n",
        "                    conv_layers.append(child)\n",
        "print(f\"Total convolutional layers: {counter}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgTtYEB4ke1F"
      },
      "outputs": [],
      "source": [
        "\n",
        "# take a look at the conv layers and the respective weights\n",
        "for weight, conv in zip(model_weights, conv_layers):\n",
        "    # print(f\"WEIGHT: {weight} \\nSHAPE: {weight.shape}\")\n",
        "    print(f\"CONV: {conv} ====> SHAPE: {weight.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEjZqcnIkpnv"
      },
      "outputs": [],
      "source": [
        "\n",
        "# visualize the first conv layer filters\n",
        "plt.figure(figsize=(20, 17))\n",
        "for i, filter in enumerate(model_weights[0]):\n",
        "    plt.subplot(8, 8, i+1) # (8, 8) because in conv0 we have 7x7 filters and total of 64 (see printed shapes)\n",
        "    plt.imshow(filter[0, :, :].detach(), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.savefig('/content/filter.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyafTwfgk8AT"
      },
      "outputs": [],
      "source": [
        "# read and visualize an image\n",
        "img = cv.imread('/content/3_b.jpg')\n",
        "img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "# define the transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((512, 512)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "img = np.array(img)\n",
        "# apply the transforms\n",
        "img = transform(img)\n",
        "print(img.size())\n",
        "# unsqueeze to add a batch dimension\n",
        "img = img.unsqueeze(0)\n",
        "print(img.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVgx3wBTlnVw"
      },
      "outputs": [],
      "source": [
        "# pass the image through all the layers\n",
        "results = [conv_layers[0](img)]\n",
        "for i in range(1, len(conv_layers)):\n",
        "    # pass the result from the last layer to the next layer\n",
        "    results.append(conv_layers[i](results[-1]))\n",
        "# make a copy of the `results`\n",
        "outputs = results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDK3Xd_QrklY"
      },
      "outputs": [],
      "source": [
        "!rm -r *.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TepOFMnFl5Gh"
      },
      "outputs": [],
      "source": [
        "# visualize 64 features from each layer\n",
        "# (although there are more feature maps in the upper layers)\n",
        "for num_layer in range(len(outputs)):\n",
        "    plt.figure(figsize=(30, 30))\n",
        "    layer_viz = outputs[num_layer][0, :, :, :]\n",
        "    layer_viz = layer_viz.data\n",
        "    print(layer_viz.size())\n",
        "    for i, filter in enumerate(layer_viz):\n",
        "\n",
        "        if i == 1:\n",
        "          break\n",
        "        plt.imshow(filter, cmap='gray')\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "\n",
        "        print(f\"Saving layer {num_layer} feature maps...\")\n",
        "        plt.savefig(f\"/content/layer_{num_layer}.png\")\n",
        "      # plt.show()\n",
        "        plt.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "VbPsoy5AEe02",
        "N-g1fSBLo7Jb"
      ],
      "provenance": [],
      "mount_file_id": "1dxYJoS8GbYnI-mmHcDasYnQuK5pEC9S9",
      "authorship_tag": "ABX9TyNyA6GoEIi3O+48OBm7x059"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03687c1afce047508dd2e3f8e4e1f1c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c70fbeda19564c109bfc8fdb56800962",
              "IPY_MODEL_34ce3d550a464cb09a7a6bad8e192c72",
              "IPY_MODEL_3a10a967a52e4a5c8f7ea198494e3f74"
            ],
            "layout": "IPY_MODEL_922f1db598764384873f93057cb41fea"
          }
        },
        "c70fbeda19564c109bfc8fdb56800962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_298b5a4ae2474c46be31211249646573",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ecd9a53da50c41b8b1b62caaafa76f3d",
            "value": "100%"
          }
        },
        "34ce3d550a464cb09a7a6bad8e192c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cd996d8823d46debdbe5363faab4e89",
            "max": 66217168,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c79504cdff644537a518272d6d54c866",
            "value": 66217168
          }
        },
        "3a10a967a52e4a5c8f7ea198494e3f74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28c91ea4d1584ba49a9be6ff3cf4b5fc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_49ba7c811fea4f4aa67a9b80d8e6e600",
            "value": " 66.2M/66.2M [00:02&lt;00:00, 31.0MiB/s]"
          }
        },
        "922f1db598764384873f93057cb41fea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "298b5a4ae2474c46be31211249646573": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecd9a53da50c41b8b1b62caaafa76f3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cd996d8823d46debdbe5363faab4e89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c79504cdff644537a518272d6d54c866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28c91ea4d1584ba49a9be6ff3cf4b5fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49ba7c811fea4f4aa67a9b80d8e6e600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}